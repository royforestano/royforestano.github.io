---
---

@string{aps = {American Physical Society,}}






@article{FORESTANO2023138306,
	abstract = {Deep learning was recently successfully used in deriving symmetry transformations that preserve important physics quantities. Being completely agnostic, these techniques postpone the identification of the discovered symmetries to a later stage. In this letter we propose methods for examining and identifying the group-theoretic structure of such machine-learned symmetries. We design loss functions which probe the subalgebra structure either during the deep learning stage of symmetry discovery or in a subsequent post-processing stage. We illustrate the new methods with examples from the U(n) Lie group family, obtaining the respective subalgebra decompositions. As an application to particle physics, we demonstrate the identification of the residual symmetries after the spontaneous breaking of non-Abelian gauge symmetries like SU(3) and SU(5) which are commonly used in model building.},
	author = {Roy T. Forestano and Konstantin T. Matchev and Katia Matcheva and Alexander Roman and Eyup B. Unlu and Sarunas Verner},
	doi = {https://doi.org/10.1016/j.physletb.2023.138306},
	issn = {0370-2693},
	journal = {Physics Letters B},
	pages = {138306},
	title = {Identifying the group-theoretic structure of machine-learned symmetries},
	url = {https://www.sciencedirect.com/science/article/pii/S0370269323006408},
	volume = {847},
	year = {2023},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0370269323006408},
	bdsk-url-2 = {https://doi.org/10.1016/j.physletb.2023.138306}
}





@article{Forestano_2023,
	abstract = {The next generation of telescopes will yield a substantial increase in the availability of high-quality spectroscopic data for thousands of exoplanets. The sheer volume of data and number of planets to be analyzed greatly motivate the development of new, fast, and efficient methods for flagging interesting planets for reobservation and detailed analysis. We advocate the application of machine learning (ML) techniques for anomaly (novelty) detection to exoplanet transit spectra, with the goal of identifying planets with unusual chemical composition and even searching for unknown biosignatures. We successfully demonstrate the feasibility of two popular anomaly detection methods (local outlier factor and one-class support vector machine) on a large public database of synthetic spectra. We consider several test cases, each with different levels of instrumental noise. In each case, we use receiver operating characteristic curves to quantify and compare the performance of the two ML techniques.},
	author = {Roy T. Forestano and Konstantin T. Matchev and Katia Matcheva and Eyup B. Unlu},
	doi = {10.3847/1538-4357/ad0047},
	journal = {The Astrophysical Journal},
	month = {nov},
	number = {2},
	pages = {106},
	publisher = {The American Astronomical Society},
	title = {Searching for Novel Chemistry in Exoplanetary Atmospheres Using Machine Learning for Anomaly Detection},
	url = {https://dx.doi.org/10.3847/1538-4357/ad0047},
	volume = {958},
	year = {2023},
	bdsk-url-1 = {https://dx.doi.org/10.3847/1538-4357/ad0047}}



@article{unlu2023reproducing,
      title={Reproducing Bayesian Posterior Distributions for Exoplanet Atmospheric Parameter Retrievals with a Machine Learning Surrogate Model}, 
      author={Eyup B. Unlu and Roy T. Forestano and Konstantin T. Matchev and Katia Matcheva},
      year={2023},
      eprint={2310.10521},
      archivePrefix={arXiv},
      primaryClass={astro-ph.EP}
}


@article{FORESTANO2023138266,
	abstract = {Recent work has applied supervised deep learning to derive continuous symmetry transformations that preserve the data labels and to obtain the corresponding algebras of symmetry generators. This letter introduces two improved algorithms that significantly speed up the discovery of these symmetry transformations. The new methods are demonstrated by deriving the complete set of generators for the unitary groups U(n) and the exceptional Lie groups G2, F4, and E6. A third post-processing algorithm renders the found generators in sparse form. We benchmark the performance improvement of the new algorithms relative to the standard approach. Given the significant complexity of the exceptional Lie groups, our results demonstrate that this machine-learning method for discovering symmetries is completely general and can be applied to a wide variety of labeled datasets.},
	author = {Roy T. Forestano and Konstantin T. Matchev and Katia Matcheva and Alexander Roman and Eyup B. Unlu and Sarunas Verner},
	doi = {https://doi.org/10.1016/j.physletb.2023.138266},
	issn = {0370-2693},
	journal = {Physics Letters B},
	pages = {138266},
	title = {Accelerated discovery of machine-learned symmetries: Deriving the exceptional Lie groups G2, F4 and E6},
	url = {https://www.sciencedirect.com/science/article/pii/S0370269323006007},
	volume = {847},
	year = {2023},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0370269323006007},
	bdsk-url-2 = {https://doi.org/10.1016/j.physletb.2023.138266}}





@inproceedings{pmlr-v220-yip23a,
	abstract = {Exo-atmospheric studies, i.e. the study of exoplanetary atmospheres, is an emerging frontier in Planetary Science. To understand the physical properties of hundreds of exoplanets, astronomers have traditionally relied on sampling-based methods. However, with the growing number of exoplanet detections (i.e. increased data quantity) and advancements in technology from telescopes such as JWST and Ariel (i.e. improved data quality), there is a need for more scalable data analysis techniques. The Ariel Data Challenge 2022 aims to find interdisciplinary solutions from the NeurIPS community. Results from the challenge indicate that machine learning (ML) models have the potential to provide quick insights for thousands of planets and millions of atmospheric models. However, the machine learning models are not immune to data drifts, and future research should investigate ways to quantify and mitigate their negative impact.},
	author = {Yip, Kai Hou and Changeat, Quentin and Waldmann, Ingo and Unlu, Eyup B. and Forestano, Roy T. and Roman, Alexander and Matcheva, Katia and Matchev, Konstantin T. and Stefanov, Stefan and Podsztavek, Ond\vrej and Morvan, Mario and Nikolaou, Nikolaos and Al-Refaie, Ahmed and Jenner, Clare and Johnson, Chris and Tsiaras, Angelos and Edwards, Billy and Alves de Oliveira, Catarina and Thiyagalingam, Jeyan and Lagage, Pierre-Olivier and Cho, James and Tinetti, Giovanna},
	booktitle = {Proceedings of the NeurIPS 2022 Competitions Track},
	editor = {Ciccone, Marco and Stolovitzky, Gustavo and Albrecht, Jacob},
	month = {28 Nov--09 Dec},
	pages = {1--17},
	pdf = {https://proceedings.mlr.press/v220/yip23a/yip23a.pdf},
	publisher = {PMLR},
	series = {Proceedings of Machine Learning Research},
	title = {Lessons Learned from Ariel Data Challenge 2022 - Inferring Physical Properties of Exoplanets From Next-Generation Telescopes},
	url = {https://proceedings.mlr.press/v220/yip23a.html},
	volume = {220},
	year = {2022},
	bdsk-url-1 = {https://proceedings.mlr.press/v220/yip23a.html}}




@article{FORESTANO2023138086,
	abstract = {Recent work has used deep learning to derive symmetry transformations, which preserve conserved quantities, and to obtain the corresponding algebras of generators. In this letter, we extend this technique to derive sparse representations of arbitrary Lie algebras. We show that our method reproduces the canonical (sparse) representations of the generators of the Lorentz group, as well as the U(n) and SU(n) families of Lie groups. This approach is completely general and can be used to find the infinitesimal generators for any Lie group.},
	author = {Roy T. Forestano and Konstantin T. Matchev and Katia Matcheva and Alexander Roman and Eyup B. Unlu and Sarunas Verner},
	doi = {https://doi.org/10.1016/j.physletb.2023.138086},
	issn = {0370-2693},
	journal = {Physics Letters B},
	pages = {138086},
	title = {Discovering sparse representations of Lie groups with machine learning},
	url = {https://www.sciencedirect.com/science/article/pii/S0370269323004203},
	volume = {844},
	year = {2023},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0370269323004203},
	bdsk-url-2 = {https://doi.org/10.1016/j.physletb.2023.138086}}





@article{sym15071352,
	abstract = {A fundamental task in data science is the discovery, description, and identification of any symmetries present in the data. We developed a deep learning methodology for the simultaneous discovery of multiple non-trivial continuous symmetries across an entire labeled dataset. The symmetry transformations and the corresponding generators are modeled with fully connected neural networks trained with a specially constructed loss function, ensuring the desired symmetry properties. The two new elements in this work are the use of a reduced-dimensionality latent space and the generalization to invariant transformations with respect to high-dimensional oracles. The method is demonstrated with several examples on the MNIST digit dataset, where the oracle is provided by the 10-dimensional vector of logits of a trained classifier. We find classes of symmetries that transform each image from the dataset into new synthetic images while conserving the values of the logits. We illustrate these transformations as lines of equal probability (&ldquo;flows&rdquo;) in the reduced latent space. These results show that symmetries in the data can be successfully searched for and identified as interpretable non-trivial transformations in the equivalent latent space.},
	article-number = {1352},
	author = {Roman, Alexander and Forestano, Roy T. and Matchev, Konstantin T. and Matcheva, Katia and Unlu, Eyup B.},
	doi = {10.3390/sym15071352},
	issn = {2073-8994},
	journal = {Symmetry},
	number = {7},
	title = {Oracle-Preserving Latent Flows},
	url = {https://www.mdpi.com/2073-8994/15/7/1352},
	volume = {15},
	year = {2023},
	bdsk-url-1 = {https://www.mdpi.com/2073-8994/15/7/1352},
	bdsk-url-2 = {https://doi.org/10.3390/sym15071352}}






@article{Forestano_2023,
	abstract = {We design a deep-learning algorithm for the discovery and identification of the continuous group of symmetries present in a labeled dataset. We use fully connected neural networks to model the symmetry transformations and the corresponding generators. The constructed loss functions ensure that the applied transformations are symmetries and the corresponding set of generators forms a closed (sub)algebra. Our procedure is validated with several examples illustrating different types of conserved quantities preserved by symmetry. In the process of deriving the full set of symmetries, we analyze the complete subgroup structure of the rotation groups SO(2), SO(3), and SO(4), and of the Lorentz group . Other examples include squeeze mapping, piecewise discontinuous labels, and SO(10), demonstrating that our method is completely general, with many possible applications in physics and data science. Our study also opens the door for using a machine learning approach in the mathematical study of Lie groups and their properties.},
	author = {Roy T Forestano and Konstantin T Matchev and Katia Matcheva and Alexander Roman and Eyup B Unlu and Sarunas Verner},
	doi = {10.1088/2632-2153/acd989},
	journal = {Machine Learning: Science and Technology},
	month = {jun},
	number = {2},
	pages = {025027},
	publisher = {IOP Publishing},
	title = {Deep learning symmetries and their Lie groups, algebras, and subalgebras from first principles},
	url = {https://dx.doi.org/10.1088/2632-2153/acd989},
	volume = {4},
	year = {2023},
	bdsk-url-1 = {https://dx.doi.org/10.1088/2632-2153/acd989},
  preview={SO10_generators.png}
}


